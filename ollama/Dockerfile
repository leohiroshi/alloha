# Dockerfile para servidor Ollama
FROM ollama/ollama:latest

# Instala curl para health checks
RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*

# Define argumentos de build
ARG OLLAMA_MODELS="llama3.1,llama3.2-vision"

# Cria diret√≥rio para modelos
RUN mkdir -p /root/.ollama

# Exp√µe a porta padr√£o do Ollama
EXPOSE 11434

# Script para inicializar e baixar modelos
COPY <<EOF /start-ollama.sh
#!/bin/bash
set -e

echo "ü¶ô Iniciando servidor Ollama..."

# Inicia o servidor Ollama em background
ollama serve &
OLLAMA_PID=$!

# Aguarda o servidor estar pronto
echo "‚è≥ Aguardando servidor Ollama ficar dispon√≠vel..."
while ! curl -s http://localhost:11434/api/tags > /dev/null; do
    sleep 2
done

echo "‚úÖ Servidor Ollama est√° rodando!"

# Baixa os modelos especificados
IFS=',' read -ra MODELS <<< "$OLLAMA_MODELS"
for model in "${MODELS[@]}"; do
    model=$(echo "$model" | xargs) # Remove espa√ßos
    if [ ! -z "$model" ]; then
        echo "üì• Baixando modelo: $model"
        ollama pull "$model" || echo "‚ùå Erro ao baixar modelo: $model"
    fi
done

echo "üéâ Todos os modelos foram processados!"

# Mant√©m o processo principal rodando
wait $OLLAMA_PID
EOF

# Torna o script execut√°vel
RUN chmod +x /start-ollama.sh

# Define vari√°veis de ambiente
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_MODELS=${OLLAMA_MODELS}

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Comando para iniciar
CMD ["/start-ollama.sh"]