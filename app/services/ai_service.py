import aiohttp
import logging
import os
import json
import re
from typing import Optional, Dict, List
from datetime import datetime

logger = logging.getLogger(__name__)

class AIService:
    def __init__(self):
        self.api_key = os.getenv("ABACUS_API_KEY", "")
        self.base_url = "https://api.abacus.ai"
        self.provider = os.getenv("AI_PROVIDER", "abacus")
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # Cache de conversas por usuÃ¡rio
        self.conversation_context = {}
        
        # Importar property_intelligence de forma lazy para evitar importaÃ§Ã£o circular
        self._property_intelligence = None
        
        # Base de conhecimento sobre imÃ³veis
        self.property_knowledge = {
            "tipos": ["apartamento", "casa", "kitnet", "studio", "cobertura", "terreno", "comercial"],
            "regioes": ["centro", "zona sul", "zona norte", "zona oeste", "zona leste"],
            "faixas_preco": {
                "baixo": "atÃ© R$ 200.000",
                "medio": "R$ 200.000 - R$ 500.000", 
                "alto": "R$ 500.000 - R$ 1.000.000",
                "premium": "acima de R$ 1.000.000"
            },
            "caracteristicas": ["quartos", "banheiros", "vagas", "area", "piscina", "churrasqueira"]
        }
    
    @property
    def property_intelligence(self):
        """Lazy loading da property intelligence para evitar importaÃ§Ã£o circular"""
        if self._property_intelligence is None:
            try:
                from .property_intelligence import property_intelligence
                self._property_intelligence = property_intelligence
            except ImportError:
                self._property_intelligence = None
        return self._property_intelligence
    
    async def generate_response(self, message: str, user_phone: str) -> str:
        """Gerar resposta inteligente usando Abacus AI com contexto"""
        try:
            if not self.api_key:
                return await self._fallback_response(message)
            
            # Analisar intenÃ§Ã£o do usuÃ¡rio
            intent = await self._analyze_intent(message)
            
            # Recuperar contexto da conversa do Firebase
            context = await self._get_conversation_context_from_db(user_phone)
            
            # Atualizar contexto em memÃ³ria
            self._update_conversation_context(user_phone, message, intent)
            
            # Gerar resposta baseada na intenÃ§Ã£o e contexto
            response = await self._generate_contextual_response(message, intent, context)
            
            return response
                
        except Exception as e:
            logger.error(f"Error generating AI response: {str(e)}")
            return "Desculpe, houve um problema. Tente novamente em alguns instantes."
    
    async def _get_conversation_context_from_db(self, user_phone: str) -> Dict:
        """Recuperar contexto da conversa do banco de dados"""
        try:
            # Importar aqui para evitar importaÃ§Ã£o circular
            from app.services.database_service import DatabaseService
            
            db_service = DatabaseService()
            
            # Obter histÃ³rico de conversas
            history = await db_service.get_conversation_history(user_phone, limit=5)
            
            # Processar histÃ³rico para criar contexto
            conversation_context = {
                "messages": history,
                "user_phone": user_phone,
                "message_count": len(history),
                "recent_topics": []
            }
            
            # Extrair tÃ³picos recentes das mensagens
            for msg in history:
                if msg.get("type") == "received":
                    # Analisar mensagem para extrair tÃ³picos
                    if any(word in msg.get("message", "").lower() for word in ["casa", "apartamento", "imÃ³vel", "propriedade"]):
                        conversation_context["recent_topics"].append("imoveis")
                    elif any(word in msg.get("message", "").lower() for word in ["preÃ§o", "valor", "custo", "quanto"]):
                        conversation_context["recent_topics"].append("precos")
                    elif any(word in msg.get("message", "").lower() for word in ["visita", "agendar", "ver", "mostrar"]):
                        conversation_context["recent_topics"].append("agendamento")
            
            return conversation_context
            
        except Exception as e:
            logger.error(f"Error getting conversation context from DB: {str(e)}")
            # Fallback para contexto em memÃ³ria
            return self._get_conversation_context(user_phone)
    
    async def _analyze_intent(self, message: str) -> Dict:
        """Analisar intenÃ§Ã£o da mensagem"""
        message_lower = message.lower()
        
        intent = {
            "type": "unknown",
            "confidence": 0.0,
            "entities": {}
        }
        
        # Detectar saudaÃ§Ãµes
        if any(word in message_lower for word in ["oi", "olÃ¡", "hello", "hi", "bom dia", "boa tarde", "boa noite"]):
            intent["type"] = "greeting"
            intent["confidence"] = 0.9
        
        # Detectar busca por imÃ³veis
        elif any(word in message_lower for word in ["apartamento", "casa", "imÃ³vel", "comprar", "alugar"]):
            intent["type"] = "property_search"
            intent["confidence"] = 0.8
            
            # Extrair entidades
            for tipo in self.property_knowledge["tipos"]:
                if tipo in message_lower:
                    intent["entities"]["property_type"] = tipo
            
            for regiao in self.property_knowledge["regioes"]:
                if regiao in message_lower:
                    intent["entities"]["location"] = regiao
            
            # Extrair nÃºmeros (quartos, preÃ§o)
            numbers = re.findall(r'\d+', message)
            if numbers:
                intent["entities"]["numbers"] = numbers
        
        # Detectar consulta de preÃ§o
        elif any(word in message_lower for word in ["preÃ§o", "valor", "quanto", "custo"]):
            intent["type"] = "price_inquiry"
            intent["confidence"] = 0.8
        
        # Detectar agendamento
        elif any(word in message_lower for word in ["visita", "agendar", "ver", "conhecer"]):
            intent["type"] = "schedule_visit"
            intent["confidence"] = 0.8
        
        # Detectar informaÃ§Ãµes
        elif any(word in message_lower for word in ["documentos", "financiamento", "fies", "itbi"]):
            intent["type"] = "information"
            intent["confidence"] = 0.7
        
        return intent
    
    def _get_conversation_context(self, user_phone: str) -> Dict:
        """Recuperar contexto da conversa"""
        if user_phone not in self.conversation_context:
            self.conversation_context[user_phone] = {
                "messages": [],
                "preferences": {},
                "last_intent": None,
                "created_at": datetime.now()
            }
        return self.conversation_context[user_phone]
    
    def _update_conversation_context(self, user_phone: str, message: str, intent: Dict):
        """Atualizar contexto da conversa"""
        context = self._get_conversation_context(user_phone)
        context["messages"].append({
            "message": message,
            "intent": intent,
            "timestamp": datetime.now()
        })
        context["last_intent"] = intent["type"]
        
        # Manter apenas Ãºltimas 10 mensagens
        if len(context["messages"]) > 10:
            context["messages"] = context["messages"][-10:]
    
    async def _generate_contextual_response(self, message: str, intent: Dict, context: Dict) -> str:
        """Gerar resposta baseada no contexto"""
        intent_type = intent["type"]
        
        if intent_type == "greeting":
            return await self._handle_greeting(context)
        elif intent_type == "property_search":
            return await self._handle_property_search(message, intent, context)
        elif intent_type == "price_inquiry":
            return await self._handle_price_inquiry(message, intent, context)
        elif intent_type == "schedule_visit":
            return await self._handle_schedule_visit(message, intent, context)
        elif intent_type == "information":
            return await self._handle_information_request(message, intent, context)
        else:
            return await self._handle_general_inquiry(message, context)
    
    async def _handle_greeting(self, context: Dict) -> str:
        """Responder saudaÃ§Ãµes"""
        if len(context["messages"]) == 1:  # Primeira interaÃ§Ã£o
            return """ğŸ  OlÃ¡! Bem-vindo Ã  Alloha! 

Sou seu assistente especializado em imÃ³veis. Posso ajudar vocÃª a:
â€¢ Encontrar apartamentos e casas
â€¢ InformaÃ§Ãµes sobre preÃ§os
â€¢ Agendar visitas
â€¢ Dicas de financiamento

O que vocÃª procura hoje?"""
        else:
            return "OlÃ¡ novamente! Como posso ajudÃ¡-lo hoje? ğŸ˜Š"
    
    async def _handle_property_search(self, message: str, intent: Dict, context: Dict) -> str:
        """Lidar com busca por imÃ³veis usando inteligÃªncia imobiliÃ¡ria"""
        try:
            # Verificar se temos property_intelligence disponÃ­vel
            if self.property_intelligence:
                # Usar o sistema de inteligÃªncia imobiliÃ¡ria
                user_id = context.get('user_phone', 'unknown')
                response = await self.property_intelligence.process_property_inquiry(message, user_id)
                return response
            else:
                # Fallback para resposta bÃ¡sica
                entities = intent.get("entities", {})
                
                # Criar prompt contextual para Abacus AI
                system_prompt = """VocÃª Ã© a Sofia! A assistente virtual da Allega ImÃ³veis.
                Responda de forma amigÃ¡vel e profissional sobre busca de imÃ³veis para venda e locaÃ§Ã£o.
                Seja especÃ­fico e Ãºtil. Limite a resposta a 300 caracteres.
                
                InformaÃ§Ãµes da Allega ImÃ³veis:
                - Site: https://www.allegaimoveis.com
                - Vendas: (41) 99214-6670
                - LocaÃ§Ã£o: (41) 99223-0874
                - Especialistas em imÃ³veis residenciais e comerciais
                - Atendimento personalizado e consultoria completa"""
                
                context_info = ""
                if entities:
                    context_info = f"Cliente interessado em: {entities}"
                
                user_prompt = f"""Cliente busca imÃ³vel: {message}
                Contexto: {context_info}
                
                Responda oferecendo ajuda e pedindo mais detalhes especÃ­ficos."""
                
                # Tentar usar Abacus AI
                response = await self._call_abacus_ai(system_prompt, user_prompt)
                
                if response:
                    return response
                else:
                    # Resposta de fallback
                    return self._get_property_search_fallback(message, entities)
                    
        except Exception as e:
            logger.error(f"Erro em _handle_property_search: {str(e)}")
            return "ğŸ  Entendi que vocÃª procura um imÃ³vel! Pode me contar mais detalhes como tipo (casa/apartamento), quantos quartos, regiÃ£o preferida e faixa de preÃ§o? Assim posso ajudar melhor!"
    
    def _get_property_search_fallback(self, message: str, entities: Dict) -> str:
        """Resposta de fallback para busca de imÃ³veis"""
        response = "ğŸ” Ã“timo! Vamos encontrar o imÃ³vel ideal para vocÃª.\n\n"
        
        if "property_type" in entities:
            response += f"VocÃª estÃ¡ interessado em {entities['property_type']}. "
        
        if "location" in entities:
            response += f"Na regiÃ£o {entities['location']}. "
        
        response += "\nPode me contar mais sobre suas preferÃªncias? (quartos, orÃ§amento, etc.)"
        
        return response
    
    async def _handle_price_inquiry(self, message: str, intent: Dict, context: Dict) -> str:
        """Lidar com consultas de preÃ§o"""
        system_prompt = """VocÃª Ã© um especialista em preÃ§os de imÃ³veis da Alloha.
        ForneÃ§a informaÃ§Ãµes realistas sobre faixas de preÃ§o.
        Seja especÃ­fico e Ãºtil. MÃ¡ximo 300 caracteres."""
        
        ai_response = await self._call_abacus_api(system_prompt, f"Cliente pergunta sobre preÃ§os: {message}")
        
        if ai_response:
            return ai_response
        
        return """ğŸ’° Os preÃ§os variam conforme localizaÃ§Ã£o e caracterÃ­sticas:

â€¢ Apartamentos: R$ 150k - R$ 800k+
â€¢ Casas: R$ 200k - R$ 1.5M+
â€¢ Kitnets: R$ 80k - R$ 200k

Que tipo de imÃ³vel te interessa? Posso dar valores mais especÃ­ficos!"""
    
    async def _handle_schedule_visit(self, message: str, intent: Dict, context: Dict) -> str:
        """Lidar com agendamento de visitas"""
        return """ğŸ“… Perfeito! Vamos agendar sua visita.

Para agilizar o processo, preciso de:
â€¢ Seu nome completo
â€¢ ImÃ³vel de interesse
â€¢ Dias/horÃ¡rios de preferÃªncia

Um corretor entrarÃ¡ em contato em atÃ© 2h para confirmar!

Qual imÃ³vel gostaria de visitar?"""
    
    async def _handle_information_request(self, message: str, intent: Dict, context: Dict) -> str:
        """Lidar com pedidos de informaÃ§Ã£o"""
        system_prompt = """VocÃª Ã© um consultor imobiliÃ¡rio da Alloha especialista em documentaÃ§Ã£o e financiamento.
        ForneÃ§a informaÃ§Ãµes prÃ¡ticas e Ãºteis. MÃ¡ximo 300 caracteres."""
        
        ai_response = await self._call_abacus_api(system_prompt, f"Cliente pergunta: {message}")
        
        if ai_response:
            return ai_response
        
        return """ğŸ“‹ Posso ajudar com informaÃ§Ãµes sobre:

â€¢ DocumentaÃ§Ã£o necessÃ¡ria
â€¢ Financiamento e FGTS
â€¢ ITBI e custos extras
â€¢ Processo de compra/venda

Sobre o que vocÃª gostaria de saber?"""
    
    async def _handle_general_inquiry(self, message: str, context: Dict) -> str:
        """Lidar com perguntas gerais"""
        system_prompt = """VocÃª Ã© o assistente da Alloha ImÃ³veis.
        Responda de forma amigÃ¡vel e direcione para serviÃ§os imobiliÃ¡rios.
        MÃ¡ximo 250 caracteres."""
        
        ai_response = await self._call_abacus_api(system_prompt, f"Cliente pergunta: {message}")
        
        if ai_response:
            return ai_response
        
        return f"""ğŸ¤– Entendi: "{message}"

Como especialista em imÃ³veis, posso ajudar com:
â€¢ Busca de apartamentos/casas
â€¢ InformaÃ§Ãµes de preÃ§os
â€¢ Agendamento de visitas
â€¢ DocumentaÃ§Ã£o

Como posso ajudÃ¡-lo hoje?"""
    
    async def _fallback_response(self, message: str) -> str:
        """Resposta quando IA nÃ£o estÃ¡ disponÃ­vel"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["oi", "olÃ¡", "hello"]):
            return "ğŸ  OlÃ¡! Sou o assistente da Alloha. Como posso ajudÃ¡-lo com imÃ³veis?"
        elif any(word in message_lower for word in ["apartamento", "casa"]):
            return "ğŸ” Ã“timo! Que tipo de imÃ³vel vocÃª procura? Em qual regiÃ£o?"
        elif any(word in message_lower for word in ["preÃ§o", "valor"]):
            return "ğŸ’° Posso ajudar com informaÃ§Ãµes de preÃ§os. Que tipo de imÃ³vel te interessa?"
        else:
            return "ğŸ¤– OlÃ¡! Sou especialista em imÃ³veis. Como posso ajudÃ¡-lo hoje?"

    async def test_abacus_image_support(self, image_base64: str) -> Dict[str, Any]:
        """Testar se Abacus suporta anÃ¡lise de imagem"""
        if not self.api_key:
            return {"error": "API key nÃ£o configurada", "supports_vision": False}
        
        try:
            # Teste 1: Formato OpenAI Vision
            payload_vision = {
                "model": "gpt-4-vision-preview",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "Analise esta imagem de imÃ³vel"},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                            }
                        ]
                    }
                ],
                "max_tokens": 150
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload_vision,
                    timeout=aiohttp.ClientTimeout(total=15)
                ) as response:
                    
                    result = {
                        "status": response.status,
                        "supports_vision": response.status == 200,
                        "endpoint_tested": "/chat/completions with vision"
                    }
                    
                    if response.status == 200:
                        data = await response.json()
                        result["success"] = True
                        result["response"] = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                        logger.info("âœ… Abacus suporta anÃ¡lise de imagem!")
                    else:
                        error_text = await response.text()
                        result["error"] = error_text
                        logger.info(f"âŒ Abacus nÃ£o suporta visÃ£o: {response.status}")
                    
                    return result
                    
        except Exception as e:
            logger.error(f"Erro testando Abacus vision: {str(e)}")
            return {
                "error": str(e),
                "supports_vision": False,
                "test_failed": True
            }

    async def analyze_image_with_abacus(self, image_base64: str, prompt: str = "") -> Optional[str]:
        """Analisar imagem usando Abacus AI (se suportado)"""
        if not self.api_key:
            return None
            
        try:
            # Prompt padrÃ£o se nÃ£o fornecido
            if not prompt:
                prompt = """Analise esta imagem de imÃ³vel brasileiro e forneÃ§a:
                1. Tipo de imÃ³vel (casa, apartamento, etc.)
                2. CaracterÃ­sticas visÃ­veis
                3. Estado de conservaÃ§Ã£o
                4. Qualidade para marketing imobiliÃ¡rio
                
                Seja especÃ­fico e Ãºtil para corretores."""
            
            # Tentar formato vision
            payload = {
                "model": "gpt-4-vision-preview",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}",
                                    "detail": "low"  # Para economizar tokens
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 300,
                "temperature": 0.1
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=20)
                ) as response:
                    
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"]
                        logger.info("âœ… AnÃ¡lise de imagem com Abacus realizada!")
                        return content
                    else:
                        error_text = await response.text()
                        logger.warning(f"Abacus vision failed: {response.status} - {error_text}")
                        return None
                        
        except Exception as e:
            logger.error(f"Erro na anÃ¡lise de imagem com Abacus: {str(e)}")
            return None

    async def _call_abacus_api(self, system_prompt: str, user_prompt: str) -> Optional[str]:
        """Chamar API do Abacus AI"""
        try:
            # ConfiguraÃ§Ã£o especÃ­fica para Abacus AI
            payload = {
                "model": "gpt-3.5-turbo",  # Ou o modelo disponÃ­vel no Abacus
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "max_tokens": 200,
                "temperature": 0.7
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions", 
                    headers=self.headers, 
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        content = data["choices"][0]["message"]["content"].strip()
                        # Limitar tamanho para WhatsApp
                        return content[:300] if len(content) > 300 else content
                    else:
                        error_text = await response.text()
                        logger.error(f"Abacus API error: {response.status} - {error_text}")
                        return None
                        
        except Exception as e:
            logger.error(f"Error calling Abacus API: {str(e)}")
            return None
    
    def is_available(self) -> bool:
        """Verificar se o serviÃ§o de AI estÃ¡ disponÃ­vel"""
        return bool(self.api_key)
    
    async def get_property_suggestions(self, criteria: str, user_phone: str) -> str:
        """Sugerir imÃ³veis baseado em critÃ©rios com contexto"""
        try:
            context = self._get_conversation_context(user_phone)
            
            system_prompt = """VocÃª Ã© um especialista em imÃ³veis da Alloha.
            Sugira imÃ³veis especÃ­ficos baseado nos critÃ©rios do cliente.
            Inclua tipos, preÃ§os estimados e localizaÃ§Ãµes.
            Seja especÃ­fico e Ãºtil. MÃ¡ximo 400 caracteres."""
            
            user_prompt = f"""CritÃ©rios do cliente: {criteria}
            
            HistÃ³rico da conversa: {context.get('messages', [])}
            
            Sugira opÃ§Ãµes de imÃ³veis adequadas."""
            
            response = await self._call_abacus_api(system_prompt, user_prompt)
            
            if response:
                return response
            
            return """ğŸ  Baseado no que vocÃª procura, temos Ã³timas opÃ§Ãµes!

Vou conectar vocÃª com um de nossos corretores especializados que tem acesso ao nosso portfÃ³lio completo.

Quer agendar uma conversa?"""
            
        except Exception as e:
            logger.error(f"Error getting property suggestions: {str(e)}")
            return "Erro ao buscar sugestÃµes. Tente novamente."
    
    def get_conversation_stats(self, user_phone: str) -> Dict:
        """Obter estatÃ­sticas da conversa"""
        context = self._get_conversation_context(user_phone)
        
        intent_counts = {}
        for msg in context["messages"]:
            intent_type = msg["intent"]["type"]
            intent_counts[intent_type] = intent_counts.get(intent_type, 0) + 1
        
        return {
            "total_messages": len(context["messages"]),
            "intent_distribution": intent_counts,
            "last_intent": context.get("last_intent"),
            "conversation_started": context.get("created_at")
        }
    
    def clear_conversation_cache(self, user_phone: str = None):
        """Limpa o cache de conversas"""
        if user_phone:
            # Limpar cache de usuÃ¡rio especÃ­fico
            if user_phone in self.conversation_context:
                del self.conversation_context[user_phone]
                logger.info(f"ğŸ—‘ï¸ Cache de conversa limpo para {user_phone}")
        else:
            # Limpar todo o cache
            self.conversation_context.clear()
            logger.info("ğŸ—‘ï¸ Todo o cache de conversas foi limpo")
